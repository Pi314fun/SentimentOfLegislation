{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell 1**: \n",
    "- This cell imports necessary modules (`json` and `os`) and reads a configuration file (`config.json`) to extract an API key for further usage. It constructs the file path dynamically based on the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Assuming your Jupyter notebook is in a directory that contains the config.json in a subdirectory\n",
    "config_path = os.path.join(os.path.dirname(os.getcwd()), 'config.json')\n",
    "\n",
    "with open(config_path, 'r') as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "api_key = config['LegiScan_api_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell 2**:\n",
    "- This cell imports additional modules (`requests` and `json`) and defines three functions:\n",
    "  - `search_laws`: Uses the LegiScan API to search for laws based on a query and returns the results.\n",
    "  - `save_to_file`: Saves data in JSON format to a specified file within the 'data' directory.\n",
    "  - `process_search_results`: Processes search results to fetch detailed information for each bill by calling another function (`fetch_bill_details`).\n",
    "  - `fetch_bill_details`: Fetches detailed information for a specific bill using the LegiScan API.\n",
    "- It iterates through a list of keywords, searches for laws related to each keyword, saves the search results, processes the search results to get detailed bill information, and saves the detailed bill information to separate JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for: E-Waste\n",
      "Details of 0 bills saved to 'data/e-waste_detailed_bills.json'.\n",
      "Searching for: electronic waste\n",
      "Details of 0 bills saved to 'data/electronic_waste_detailed_bills.json'.\n",
      "Searching for: e-scrap\n",
      "Details of 0 bills saved to 'data/e-scrap_detailed_bills.json'.\n",
      "Searching for: WEEE\n",
      "Details of 0 bills saved to 'data/weee_detailed_bills.json'.\n",
      "Searching for: sustainability\n",
      "Details of 0 bills saved to 'data/sustainability_detailed_bills.json'.\n",
      "Searching for: environmental stewardship\n",
      "Details of 0 bills saved to 'data/environmental_stewardship_detailed_bills.json'.\n",
      "Searching for: green practices\n",
      "Details of 0 bills saved to 'data/green_practices_detailed_bills.json'.\n",
      "Searching for: Right to Repair\n",
      "Details of 0 bills saved to 'data/right_to_repair_detailed_bills.json'.\n",
      "Searching for: repairability\n",
      "Details of 0 bills saved to 'data/repairability_detailed_bills.json'.\n",
      "Searching for: Planned Obsolescence\n",
      "Details of 0 bills saved to 'data/planned_obsolescence_detailed_bills.json'.\n",
      "Searching for: product lifespan\n",
      "Details of 0 bills saved to 'data/product_lifespan_detailed_bills.json'.\n",
      "Searching for: Circular Economy\n",
      "Details of 0 bills saved to 'data/circular_economy_detailed_bills.json'.\n",
      "Searching for: zero waste\n",
      "Details of 0 bills saved to 'data/zero_waste_detailed_bills.json'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def search_laws(api_key, query, state='ALL'):\n",
    "    \"\"\"Search for laws based on a query and return the results.\"\"\"\n",
    "    url = f\"https://api.legiscan.com/?key={api_key}&op=getSearch&state={state}&query={query}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_to_file(data, filename):\n",
    "    \"\"\"Save the given data to a file in JSON format.\"\"\"\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    with open(os.path.join('data', filename), 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def process_search_results(search_results, api_key):\n",
    "    \"\"\"Process search results to fetch detailed information for each bill.\"\"\"\n",
    "    detailed_bills = []\n",
    "    if 'searchresult' in search_results:\n",
    "        # Correct key for bills if it is 'bills'\n",
    "        for bill in search_results['searchresult'].get('bills', []):\n",
    "            try:\n",
    "                bill_id = bill['bill_id']\n",
    "                bill_detail = fetch_bill_details(api_key, bill_id)\n",
    "                if bill_detail:\n",
    "                    detailed_bills.append(bill_detail)\n",
    "                else:\n",
    "                    print(f\"No details found for bill ID: {bill_id}\")\n",
    "            except KeyError as e:\n",
    "                # Log to see what keys are missing or incorrect\n",
    "                print(f\"Key error: {e} in bill: {bill}\")\n",
    "    return detailed_bills\n",
    "\n",
    "\n",
    "def fetch_bill_details(api_key, bill_id):\n",
    "    \"\"\"Fetch detailed information for a specific bill.\"\"\"\n",
    "    url = f\"https://api.legiscan.com/?key={api_key}&op=getBill&id={bill_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\n",
    "            f\"Failed to fetch details for bill ID {bill_id}, Status code: {response.status_code}, Response: {response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "keywords = [\n",
    "    \"E-Waste\", \"electronic waste\", \"e-scrap\", \"WEEE\",\n",
    "    \"sustainability\", \"environmental stewardship\", \"green practices\",\n",
    "    \"Right to Repair\", \"repairability\",\n",
    "    \"Planned Obsolescence\", \"product lifespan\",\n",
    "    \"Circular Economy\", \"zero waste\"\n",
    "]\n",
    "\n",
    "# Process each keyword\n",
    "for query in keywords:\n",
    "    print(f\"Searching for: {query}\")\n",
    "    search_results = search_laws(api_key, query)\n",
    "    if search_results:\n",
    "        filename = f\"{query.replace(' ', '_').lower()}_search_results.json\"\n",
    "        save_to_file(search_results, filename)\n",
    "        detailed_bills = process_search_results(search_results, api_key)\n",
    "        detailed_filename = f\"{query.replace(' ', '_').lower()}_detailed_bills.json\"\n",
    "        save_to_file(detailed_bills, detailed_filename)\n",
    "        print(\n",
    "            f\"Details of {len(detailed_bills)} bills saved to 'data/{detailed_filename}'.\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve search results for '{query}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell 3**:\n",
    "- This cell imports additional modules (`os`, `json`, `requests`, and `pandas`) and defines three functions:\n",
    "  - `fetch_bill_details`: Re-defined to fetch detailed information for a specific bill.\n",
    "  - `extract_bill_ids`: Extracts bill IDs from a given JSON file.\n",
    "  - `process_files_and_fetch_details`: Processes each file to fetch detailed bill information for each bill ID and saves the information to a CSV file.\n",
    "- It specifies a list of file paths, processes each file to extract bill IDs, fetches detailed information for each bill, and saves all the detailed information to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detailed bills information to 'data/detailed_bills.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def fetch_bill_details(api_key, bill_id):\n",
    "    \"\"\"Fetch detailed information for a specific bill.\"\"\"\n",
    "    url = f\"https://api.legiscan.com/?key={api_key}&op=getBill&id={bill_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('bill', {})\n",
    "    else:\n",
    "        print(\n",
    "            f\"Failed to fetch details for bill ID {bill_id}, HTTP Status: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_bill_ids(file_path):\n",
    "    \"\"\"Extract bill IDs from a given JSON file.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        bill_ids = []\n",
    "        results = data.get('searchresult', {})\n",
    "        # Extract all numbered keys which contain bill details\n",
    "        for key in results:\n",
    "            if key.isdigit():  # Check if key is a digit, indicating a bill entry\n",
    "                bill_ids.append(results[key]['bill_id'])\n",
    "        return bill_ids\n",
    "\n",
    "\n",
    "def process_files_and_fetch_details(api_key, file_paths):\n",
    "    \"\"\"Process each file to fetch detailed bill information for each bill ID and save to a CSV.\"\"\"\n",
    "    all_details = []\n",
    "    for file_path in file_paths:\n",
    "        bill_ids = extract_bill_ids(file_path)\n",
    "        for bill_id in bill_ids:\n",
    "            details = fetch_bill_details(api_key, bill_id)\n",
    "            if details:\n",
    "                all_details.append(details)\n",
    "\n",
    "    # Convert list of dictionaries to a DataFrame\n",
    "    if all_details:\n",
    "        df = pd.DataFrame(all_details)\n",
    "        # Save to CSV\n",
    "        df.to_csv('data/detailed_bills.csv', index=False)\n",
    "        print(\"Saved detailed bills information to 'data/detailed_bills.csv'\")\n",
    "    else:\n",
    "        print(\"No details were found to save to CSV.\")\n",
    "\n",
    "\n",
    "file_paths = [\n",
    "    'data/e-waste_search_results.json',\n",
    "    'data/electronic_waste_search_results.json',\n",
    "    'data/e-scrap_search_results.json',\n",
    "    'data/weee_search_results.json',\n",
    "    'data/sustainability_search_results.json',\n",
    "    'data/environmental_stewardship_search_results.json',\n",
    "    'data/green_practices_search_results.json',\n",
    "    'data/right_to_repair_search_results.json',\n",
    "    'data/repairability_search_results.json',\n",
    "    'data/planned_obsolescence_search_results.json',\n",
    "    'data/product_lifespan_search_results.json',\n",
    "    'data/circular_economy_search_results.json',\n",
    "    'data/zero_waste_search_results.json'\n",
    "]\n",
    "\n",
    "process_files_and_fetch_details(api_key, file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell 4**:\n",
    "- This cell performs the following steps:\n",
    "  - Loads the data from the previously saved CSV file (`detailed_bills.csv`).\n",
    "  - Ensures the `status_date` column is of datetime type.\n",
    "  - Sorts the data by `status_date` and removes duplicate entries, keeping the most recent one.\n",
    "  - Optionally, sorts by `session_id` to ensure only the latest session information is retained.\n",
    "  - Saves the filtered data to a new CSV file (`updated_detailed_bills.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved to 'data/updated_detailed_bills.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the data\n",
    "df = pd.read_csv('data/detailed_bills.csv')\n",
    "\n",
    "# Step 2: Ensure 'status_date' is a datetime type\n",
    "df['status_date'] = pd.to_datetime(df['status_date'])\n",
    "\n",
    "# Step 3: Sort by 'status_date' and drop duplicates keeping the last entry which is the most recent\n",
    "df_sorted = df.sort_values(\n",
    "    'status_date').drop_duplicates('bill_id', keep='last')\n",
    "\n",
    "# Optional: If you want to ensure you only have the latest session information\n",
    "# This assumes 'session_id' or similar logic can determine the latest session\n",
    "df_sorted = df_sorted.sort_values(\n",
    "    'session_id').drop_duplicates('bill_id', keep='last')\n",
    "\n",
    "# Step 4: Save the filtered data to a new CSV file\n",
    "df_sorted.to_csv('data/updated_detailed_bills.csv', index=False)\n",
    "\n",
    "print(\"Updated dataset saved to 'data/updated_detailed_bills.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell 5**:\n",
    "- This cell performs the following steps:\n",
    "  - Loads the data from the previously saved CSV file (`updated_detailed_bills.csv`).\n",
    "  - Specifies the columns to keep in the filtered dataset.\n",
    "  - Reindexes the DataFrame to ensure it contains only the specified columns.\n",
    "  - Saves the filtered data to a new CSV file (`refined_detailed_bills.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined dataset saved to 'data/refined_detailed_bills.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the previously updated dataset\n",
    "df = pd.read_csv('data/updated_detailed_bills.csv')\n",
    "\n",
    "# Step 2: Specify the columns to keep\n",
    "columns_to_keep = [\n",
    "    'bill_id', 'bill_number', 'title', 'description', 'url', 'state_link',\n",
    "    'status', 'status_date', 'session_id', 'state_id', 'state', 'body_id',\n",
    "    'current_body_id', 'sponsors', 'subjects', 'texts', 'votes'\n",
    "]\n",
    "\n",
    "# Filter the DataFrame to keep only the specified columns\n",
    "df_filtered = df[columns_to_keep]\n",
    "\n",
    "# Handle any missing columns in the original data that are expected to be in columns_to_keep\n",
    "# This step ensures that if any column is missing from the data, it doesn't cause an error\n",
    "df_filtered = df_filtered.reindex(columns=columns_to_keep)\n",
    "\n",
    "# Step 3: Save the filtered data to a new CSV file\n",
    "df_filtered.to_csv('data/refined_detailed_bills.csv', index=False)\n",
    "\n",
    "print(\"Refined dataset saved to 'data/refined_detailed_bills.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell 6**:\n",
    "- This cell performs a comprehensive exploratory data analysis (EDA) on the refined dataset:\n",
    "  - Loads the dataset from `refined_detailed_bills.csv`.\n",
    "  - Displays basic information about the dataset, including the number of entries and column types.\n",
    "  - Shows data types of each column.\n",
    "  - Displays the number of non-null entries for each column.\n",
    "  - Displays the number of missing entries for each column.\n",
    "  - Shows the number of unique values for each column.\n",
    "  - Displays a preview of the first few rows of the dataset.\n",
    "  - Provides a basic statistical summary of numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 444 entries, 0 to 443\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   bill_id          444 non-null    int64 \n",
      " 1   bill_number      444 non-null    object\n",
      " 2   title            444 non-null    object\n",
      " 3   description      444 non-null    object\n",
      " 4   url              444 non-null    object\n",
      " 5   state_link       444 non-null    object\n",
      " 6   status           444 non-null    int64 \n",
      " 7   status_date      444 non-null    object\n",
      " 8   session_id       444 non-null    int64 \n",
      " 9   state_id         444 non-null    int64 \n",
      " 10  state            444 non-null    object\n",
      " 11  body_id          444 non-null    int64 \n",
      " 12  current_body_id  444 non-null    int64 \n",
      " 13  sponsors         444 non-null    object\n",
      " 14  subjects         444 non-null    object\n",
      " 15  texts            444 non-null    object\n",
      " 16  votes            444 non-null    object\n",
      "dtypes: int64(6), object(11)\n",
      "memory usage: 59.1+ KB\n",
      "None\n",
      "\n",
      "Data Types:\n",
      "bill_id             int64\n",
      "bill_number        object\n",
      "title              object\n",
      "description        object\n",
      "url                object\n",
      "state_link         object\n",
      "status              int64\n",
      "status_date        object\n",
      "session_id          int64\n",
      "state_id            int64\n",
      "state              object\n",
      "body_id             int64\n",
      "current_body_id     int64\n",
      "sponsors           object\n",
      "subjects           object\n",
      "texts              object\n",
      "votes              object\n",
      "dtype: object\n",
      "\n",
      "Non-Null Count:\n",
      "bill_id            444\n",
      "bill_number        444\n",
      "title              444\n",
      "description        444\n",
      "url                444\n",
      "state_link         444\n",
      "status             444\n",
      "status_date        444\n",
      "session_id         444\n",
      "state_id           444\n",
      "state              444\n",
      "body_id            444\n",
      "current_body_id    444\n",
      "sponsors           444\n",
      "subjects           444\n",
      "texts              444\n",
      "votes              444\n",
      "dtype: int64\n",
      "\n",
      "Missing Values Count:\n",
      "bill_id            0\n",
      "bill_number        0\n",
      "title              0\n",
      "description        0\n",
      "url                0\n",
      "state_link         0\n",
      "status             0\n",
      "status_date        0\n",
      "session_id         0\n",
      "state_id           0\n",
      "state              0\n",
      "body_id            0\n",
      "current_body_id    0\n",
      "sponsors           0\n",
      "subjects           0\n",
      "texts              0\n",
      "votes              0\n",
      "dtype: int64\n",
      "\n",
      "Unique Values Count:\n",
      "bill_id            444\n",
      "bill_number        438\n",
      "title              364\n",
      "description        394\n",
      "url                444\n",
      "state_link         443\n",
      "status               6\n",
      "status_date        174\n",
      "session_id          42\n",
      "state_id            42\n",
      "state               42\n",
      "body_id             77\n",
      "current_body_id     75\n",
      "sponsors           414\n",
      "subjects           132\n",
      "texts              444\n",
      "votes              170\n",
      "dtype: int64\n",
      "\n",
      "Preview of Data:\n",
      "   bill_id bill_number                                              title  \\\n",
      "0  1696211      HF1373  Consumer choice of fuel provided, rulemaking a...   \n",
      "1  1862762      HF4800  Original equipment manufacturer required to fa...   \n",
      "2  1862691      HF4790  State Board of Investment standards to require...   \n",
      "3  1642978        HF30  Catalytic converter purchase or acquisition re...   \n",
      "4  1856477      HF4331  Metropolitan Council abolished, duties transfe...   \n",
      "\n",
      "                                         description  \\\n",
      "0  Consumer choice of fuel provided, rulemaking a...   \n",
      "1  Original equipment manufacturer required to fa...   \n",
      "2  State Board of Investment standards to require...   \n",
      "3  Catalytic converter purchase or acquisition re...   \n",
      "4  Metropolitan Council abolished, duties transfe...   \n",
      "\n",
      "                                        url  \\\n",
      "0  https://legiscan.com/MN/bill/HF1373/2023   \n",
      "1  https://legiscan.com/MN/bill/HF4800/2023   \n",
      "2  https://legiscan.com/MN/bill/HF4790/2023   \n",
      "3    https://legiscan.com/MN/bill/HF30/2023   \n",
      "4  https://legiscan.com/MN/bill/HF4331/2023   \n",
      "\n",
      "                                          state_link  status status_date  \\\n",
      "0  https://www.revisor.mn.gov/bills/bill.php?b=Ho...       1  2023-02-06   \n",
      "1  https://www.revisor.mn.gov/bills/bill.php?b=Ho...       1  2024-03-11   \n",
      "2  https://www.revisor.mn.gov/bills/bill.php?b=Ho...       1  2024-03-11   \n",
      "3  https://www.revisor.mn.gov/bills/bill.php?b=Ho...       4  2023-03-16   \n",
      "4  https://www.revisor.mn.gov/bills/bill.php?b=Ho...       1  2024-02-28   \n",
      "\n",
      "   session_id  state_id state  body_id  current_body_id  \\\n",
      "0        1986        23    MN       55               55   \n",
      "1        1986        23    MN       55               55   \n",
      "2        1986        23    MN       55               55   \n",
      "3        1986        23    MN       55               55   \n",
      "4        1986        23    MN       55               55   \n",
      "\n",
      "                                            sponsors subjects  \\\n",
      "0  [{'people_id': 10502, 'person_hash': 'fhkyu0ol...       []   \n",
      "1  [{'people_id': 23672, 'person_hash': 'grgnrgsp...       []   \n",
      "2  [{'people_id': 23655, 'person_hash': 'wfskfwfs...       []   \n",
      "3  [{'people_id': 20458, 'person_hash': '6yy7mlgi...       []   \n",
      "4  [{'people_id': 23680, 'person_hash': '5hg1lnqf...       []   \n",
      "\n",
      "                                               texts  \\\n",
      "0  [{'doc_id': 2683228, 'date': '2023-02-06', 'ty...   \n",
      "1  [{'doc_id': 2956902, 'date': '2024-03-08', 'ty...   \n",
      "2  [{'doc_id': 2956837, 'date': '2024-03-08', 'ty...   \n",
      "3  [{'doc_id': 2623214, 'date': '2023-01-04', 'ty...   \n",
      "4  [{'doc_id': 2944327, 'date': '2024-02-27', 'ty...   \n",
      "\n",
      "                                               votes  \n",
      "0                                                 []  \n",
      "1                                                 []  \n",
      "2                                                 []  \n",
      "3  [{'roll_call_id': 1257025, 'date': '2023-02-20...  \n",
      "4                                                 []  \n",
      "\n",
      "Statistical Summary of Numeric Columns:\n",
      "            bill_id      status   session_id    state_id     body_id  \\\n",
      "count  4.440000e+02  444.000000   444.000000  444.000000  444.000000   \n",
      "mean   1.771129e+06    2.009009  2050.889640   26.396396   56.896396   \n",
      "std    6.339997e+04    1.523306    45.977853   15.238231   31.293817   \n",
      "min    1.636388e+06    1.000000  1986.000000    2.000000    1.000000   \n",
      "25%    1.714478e+06    1.000000  2016.000000   13.000000   31.000000   \n",
      "50%    1.783610e+06    1.000000  2034.000000   23.000000   54.500000   \n",
      "75%    1.821410e+06    2.250000  2111.000000   40.000000   80.000000   \n",
      "max    1.872604e+06    6.000000  2129.000000   52.000000  116.000000   \n",
      "\n",
      "       current_body_id  \n",
      "count       444.000000  \n",
      "mean         56.936937  \n",
      "std          31.288804  \n",
      "min           1.000000  \n",
      "25%          31.750000  \n",
      "50%          54.500000  \n",
      "75%          80.000000  \n",
      "max         116.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/refined_detailed_bills.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Basic Information:\")\n",
    "print(df.info())\n",
    "\n",
    "# Show data types of each column\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Display the number of non-null entries for each column\n",
    "print(\"\\nNon-Null Count:\")\n",
    "print(df.notnull().sum())\n",
    "\n",
    "# Display the number of missing entries for each column\n",
    "print(\"\\nMissing Values Count:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Show the number of unique values for each column\n",
    "print(\"\\nUnique Values Count:\")\n",
    "print(df.nunique())\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(\"\\nPreview of Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Basic statistical summary of numeric columns\n",
    "print(\"\\nStatistical Summary of Numeric Columns:\")\n",
    "print(df.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
